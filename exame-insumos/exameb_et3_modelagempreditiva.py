# -*- coding: utf-8 -*-
"""ExameB_ET3_ModelagemPreditiva.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gxout9W7Ua7SucrUx4GlYoQqZC34stcv

# Exame B - Etapa 3: Modelagem Preditiva
"""

import pandas as pd
import numpy as np
import numpy.polynomial.polynomial as pb
import scipy.stats as stats
import statsmodels.api as sm
import statsmodels.stats.api as sms
from statsmodels.stats.stattools import durbin_watson
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from itertools import combinations
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Carregamento dos dados
df_insumos = pd.read_csv("insumos_PA.csv")
df_features = pd.read_csv("features_PA.csv")

# Tratamento inicial
df_castanha = df_insumos[['Ano', '1.3 - Castanha-do-pará']].copy()
df_castanha.columns = ['ano', 'prod_ton']

df_features['Data'] = pd.to_datetime(df_features['Data'])
df_features['ano'] = df_features['Data'].dt.year

cols_clima = ['Total_Focos', 'Precipitacao_Media', 'Temp_Max_Media', 'Dias_Secos_Medio']
for col in cols_clima:
    df_features[col] = pd.to_numeric(df_features[col], errors='coerce')

df_features_anual = df_features.groupby('ano').agg({
    'Total_Focos': 'sum',
    'Precipitacao_Media': 'sum',
    'Temp_Max_Media': 'mean',
    'Dias_Secos_Medio': 'mean'
}).reset_index()

df_final = pd.merge(df_castanha, df_features_anual, on='ano').dropna()
print(f"Dados processados para {len(df_final)} anos.")

# Divisão determinística temporal (sem embaralhamento)
# Ordena por ano e corta nos últimos 20% como validação
df_final = df_final.sort_values('ano').reset_index(drop=True)

corte = int(len(df_final) * 0.80)
df_treino    = df_final.iloc[:corte].copy()
df_validacao = df_final.iloc[corte:].copy()

print("Treino:", df_treino.shape, "| Anos:", df_treino['ano'].tolist())
print("Validação:", df_validacao.shape, "| Anos:", df_validacao['ano'].tolist())

df = df_treino.copy()

"""## Modelando Relações
---

"""

# Convertendo colunas do dataframe para arrays
temperatura = np.array(df['Temp_Max_Media'])
focos = np.array(df['Total_Focos'])
dias_secos = np.array(df['Dias_Secos_Medio'])
precipitacao = np.array(df['Precipitacao_Media'])
producao = np.array(df['prod_ton'])

plt.figure(figsize=(12, 8))

# Temperatura vs Produção
plt.subplot(2,2,1)
plt.scatter(temperatura, producao)
plt.xlabel("Temperatura média")
plt.ylabel("Produção (ton)")
plt.title("Temperatura vs Produção")

# Focos vs Produção
plt.subplot(2,2,2)
plt.scatter(focos, producao)
plt.xlabel("Total focos")
plt.ylabel("Produção (ton)")
plt.title("Focos vs Produção")

# Dias secos vs Produção
plt.subplot(2,2,3)
plt.scatter(dias_secos, producao)
plt.xlabel("Dias secos")
plt.ylabel("Produção (ton)")
plt.title("Dias secos vs Produção")

# Precipitação vs Produção
plt.subplot(2,2,4)
plt.scatter(precipitacao, producao)
plt.xlabel("Precipitação")
plt.ylabel("Produção (ton)")
plt.title("Precipitação vs Produção")

plt.tight_layout()
plt.show()

# Escolha das Variáveis: Matriz de Correlação no conjunto de treino

plt.figure(figsize=(8, 6))
# Usar apenas df_treino para evitar data leakage
sns.heatmap(df_treino[['Temp_Max_Media', 'Total_Focos', 'Dias_Secos_Medio', 'Precipitacao_Media', 'prod_ton']].corr(),
            annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title("Matriz de Correlação (Dados de Treino)")
plt.show()

# Calcular o p-value das correlações para justificar a escolha
print("Testes de significância das correlações com a Produção:")
for col in ['Temp_Max_Media', 'Total_Focos', 'Dias_Secos_Medio', 'Precipitacao_Media']:
    corr, p_value = stats.pearsonr(df_treino[col], df_treino['prod_ton'])
    print(f"{col}: Correlação = {corr:.3f} | p-value = {p_value:.3f}")

"""Com base na matriz de correlação e nos testes de significância de Pearson (α = 0,05), nenhuma das variáveis climáticas apresentou relação linear estatisticamente significativa com a variável alvo. Os p-values obtidos foram: **Temperatura Máxima** = 0,980; **Total de Focos** = 0,945; **Dias Secos** = 0,390; **Precipitação** = 0,956 — todos superiores a 0,05.

Em termos de correlação absoluta, **Dias Secos** apresentou o maior valor (r = 0,353), seguido de **Total de Focos** (r = 0,029) e **Precipitação** (r = −0,023). Apesar da ausência de significância individual, prosseguimos com a regressão múltipla para avaliar se o efeito conjunto das variáveis consegue explicar a variância da produção.

## Regressão
---

### Regressão Polinomial

Foram testados modelos polinomiais de graus 1 a 4 para cada variável climática, usando o **R² ajustado** como critério de seleção — penaliza a adição de parâmetros desnecessários e evita overfitting.
"""

def regressao_polinomial(x, y, nome_var):
    plt.figure(figsize=(6,4))
    plt.scatter(x,y,label="dados")
    plt.xlabel(nome_var)
    plt.ylabel("Produção (ton)")

    n = len(x)

    ordem = np.argsort(x)
    x_ord = x[ordem]
    y_ord = y[ordem]

    for d in [1,2,3,4]:
        p = d+1

        coefs = pb.polyfit(x_ord, y_ord, d)
        yhat = pb.polyval(x_ord, coefs)
        R2 = r2_score(y_ord, yhat)
        R2ajustado = 1-(1-R2)*((n-1)/(n-p))

        plt.plot(x_ord,yhat,
                 label="grau "+str(d)+
                 " R²="+str(round(R2,3))+
                 " R²adj="+str(round(R2ajustado,3)))

    plt.legend()
    plt.title(f"Regressão polinomial - {nome_var}")
    plt.show()


# Aplicar para cada variável
regressao_polinomial(np.array(df['Temp_Max_Media']), producao, "Temperatura")
regressao_polinomial(np.array(df['Total_Focos']), producao, "Total focos")
regressao_polinomial(np.array(df['Dias_Secos_Medio']), producao, "Dias secos")
regressao_polinomial(np.array(df['Precipitacao_Media']), producao, "Precipitação")

"""Os melhores R² ajustados no treino foram obtidos por modelos de grau intermediário:

| Variável | Grau | R² Treino | R²adj Treino |
|---|---|---|---|
| Total de Focos | 3 | 0,725 | **0,519** |
| Total de Focos | 4 | 0,785 | **0,499** |
| Temperatura | 4 | 0,679 | **0,251** |
| Dias Secos | 3 | 0,547 | **0,208** |

O **Total de Focos** se destaca como a variável com maior poder explicativo no treino (R²adj = 0,519 no grau 3). As demais variáveis em graus 1 e 2 apresentaram R²adj negativo ou próximo de zero.

Contudo, o bom ajuste no treino **não se traduziu em generalização na validação** — resultado esperado e explicado pela natureza dos dados: o conjunto de treino cobre 2014–2021 com produção média de 6.900 ton, enquanto a validação (2022–2024) apresenta valores de 8.721 a 9.394 ton, consistentemente acima do máximo de treino (~8.050 ton). Trata-se de extrapolação temporal: os modelos nunca viram esse nível de produção e não conseguem generalizar para fora do intervalo de treino. A análise comparativa detalhada está na seção de Comparação de Modelos.

### Regressão Múltipla
"""

X_treino = df_treino[['Temp_Max_Media', 'Total_Focos', 'Dias_Secos_Medio', 'Precipitacao_Media']]
y_treino = df_treino['prod_ton']

# Padronização — variáveis em escalas muito diferentes
scaler = StandardScaler()
X_treino_scaled = scaler.fit_transform(X_treino)
X_treino_scaled_df = pd.DataFrame(X_treino_scaled, columns=X_treino.columns, index=X_treino.index)

X_treino_sm = sm.add_constant(X_treino_scaled_df)
modelo_stats = sm.OLS(y_treino, X_treino_sm).fit()
print(modelo_stats.summary())

"""**ANOVA (Significância Global):** O Prob(F-statistic) resultou em **0,907**, muito acima do nível de significância de 0,05. Não é possível rejeitar a hipótese nula — o modelo como um todo não é estatisticamente significativo. O R² ajustado de **−0,793** confirma que o modelo é penalizado severamente pelo número de preditores frente às apenas 8 observações de treino.

**Teste T (Coeficientes Individuais):** Nenhuma variável apresentou significância estatística individual — todos os p-values ficaram acima de 0,05:

| Variável | Coef. | p-value |
|---|---|---|
| Temperatura Máxima | −191,21 | 0,856 |
| Total de Focos | −100,23 | 0,921 |
| Dias Secos | 819,11 | 0,414 |
| Precipitação | −549,03 | 0,632 |
| Constante (intercepto) | 6.901,38 | 0,002 ✓ |

A única significância encontrada foi no intercepto (p = 0,002), sugerindo que a média histórica de produção (~6.901 ton) é informativa, mas as variáveis climáticas não acrescentam poder explicativo adicional com os dados disponíveis.

"""

# Preparando os dados de validação (aplicando o mesmo scaler do treino)
X_val = df_validacao[['Temp_Max_Media', 'Total_Focos', 'Dias_Secos_Medio', 'Precipitacao_Media']]
y_val = df_validacao['prod_ton']

X_val_scaled = scaler.transform(X_val)
X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)
X_val_sm = sm.add_constant(X_val_scaled_df)

# Fazendo predições nos dados de validação
y_pred_val = modelo_stats.predict(X_val_sm)

# Calculando métricas
rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))
mae_val = mean_absolute_error(y_val, y_pred_val)
r2_val = r2_score(y_val, y_pred_val)

print(f"Métricas de Validação (Conjunto não visto pelo modelo):")
print(f"RMSE: {rmse_val:.2f}")
print(f"MAE:  {mae_val:.2f}")
print(f"R²:   {r2_val:.4f}")

"""O desempenho na validação (anos 2022–2024) confirma o problema de extrapolação temporal:

| Métrica | Valor |
|---|---|
| RMSE | 3.338,04 ton |
| MAE | 2.913,03 ton |
| R² | −123,75 |

O R² de **−123,75** é extremamente negativo porque combina dois efeitos: (1) o modelo prevê 6.900 ton quando a produção real é 8.900 ton (erro sistemático de 2.000 ton); (2) os três anos de validação têm produções muito próximas entre si (8.721–9.394 ton), o que torna o SS_total (denominador do R²) muito pequeno (~268 mil) enquanto o SS_residual (numerador) é 11,7 milhões — amplificando artificialmente a magnitude negativa. O RMSE de 3.338 ton é a métrica mais representativa do erro real.

### Transformação Logarítmica

Testada para estabilizar a variância e reduzir o efeito de escala entre Total de Focos e Precipitação (ordens de grandeza muito superiores às demais variáveis).
"""

# Transformação Logarítmica das Variáveis

print("\n Testando Transformação Logarítmica ")

# Aplicando log1p (log(1+x)) para lidar com assimetria e grandes escalas
# Transformando a variável alvo e as variáveis preditoras com maior variância
y_treino_log = np.log1p(y_treino)
y_val_log = np.log1p(y_val)

X_treino_log = X_treino.copy()
X_treino_log['Total_Focos'] = np.log1p(X_treino_log['Total_Focos'])
X_treino_log['Precipitacao_Media'] = np.log1p(X_treino_log['Precipitacao_Media'])

X_val_log = X_val.copy()
X_val_log['Total_Focos'] = np.log1p(X_val_log['Total_Focos'])
X_val_log['Precipitacao_Media'] = np.log1p(X_val_log['Precipitacao_Media'])

# Padronizando os dados transformados
scaler_log = StandardScaler()
X_treino_log_scaled = scaler_log.fit_transform(X_treino_log)
X_val_log_scaled = scaler_log.transform(X_val_log)

# Convertendo para DataFrame e adicionando a constante
X_treino_log_sm = sm.add_constant(pd.DataFrame(X_treino_log_scaled, columns=X_treino.columns, index=X_treino.index))
X_val_log_sm = sm.add_constant(pd.DataFrame(X_val_log_scaled, columns=X_val.columns, index=X_val.index))

# Ajustando o novo modelo OLS com os dados transformados
modelo_log_stats = sm.OLS(y_treino_log, X_treino_log_sm).fit()
print("Resumo do Modelo com Transformação Logarítmica:")
print(modelo_log_stats.summary())

# Fazendo predições e validando o novo modelo
y_pred_val_log = modelo_log_stats.predict(X_val_log_sm)

# Como o Y está em log, precisamos reverter (expm1) para calcular o RMSE e MAE na escala original (toneladas)
y_val_real = np.expm1(y_val_log)
y_pred_val_real = np.expm1(y_pred_val_log)

rmse_val_log = np.sqrt(mean_squared_error(y_val_real, y_pred_val_real))
mae_val_log = mean_absolute_error(y_val_real, y_pred_val_real)
r2_val_log = r2_score(y_val_log, y_pred_val_log) # R2 avaliado na escala logarítmica

print(f"\nMétricas de Validação (Modelo LOG):")
print(f"RMSE (ton): {rmse_val_log:.2f}")
print(f"MAE (ton): {mae_val_log:.2f}")
print(f"R² (escala log): {r2_val_log:.4f}")

"""A transformação logarítmica **não produziu melhora substancial**: o modelo manteve insignificância global (Prob F = 0,898) e nenhuma variável atingiu p < 0,05. O R² ajustado no treino passou de −0,793 para **−0,764** — uma variação marginal. O RMSE na escala original foi de **3.475,47 ton**, ligeiramente superior ao modelo sem transformação (3.338,04 ton), confirmando que o problema é estrutural: insuficiência amostral e extrapolação para faixa de produção não observada no treino.

## Comparação de Modelos
---
A tabela abaixo consolida as métricas de validação para todos os modelos testados. O critério de ordenação é o **RMSE de validação** (menor erro absoluto = melhor generalização).

> **Por que o R² de validação é tão negativo em todos os modelos?**
> O R² de validação é calculado como `1 − SS_res / SS_tot`, onde `SS_tot` mede a variância dos valores reais de validação em torno da *sua própria média*. Como os três anos de validação (2022–2024) têm produções muito similares entre si (8.721–9.394 ton), o `SS_tot` é muito pequeno (268 mil). Qualquer erro de predição — mesmo de 1.900 ton — produz um `SS_res` (11 milhões) muito maior que o `SS_tot`, resultando em R² muito negativo. **O R² negativo aqui não indica necessariamente um modelo inútil: indica extrapolação temporal** — os modelos foram treinados com produção média de 6.900 ton (2014–2021) e precisam prever 8.900 ton (2022–2024), faixa nunca observada. O **RMSE é a métrica mais adequada** para comparação neste contexto.
"""

resultados_modelos = []

variaveis = ['Temp_Max_Media', 'Total_Focos', 'Dias_Secos_Medio', 'Precipitacao_Media']
nomes_var = {'Temp_Max_Media': 'Temperatura', 'Total_Focos': 'Focos',
             'Dias_Secos_Medio': 'Dias Secos', 'Precipitacao_Media': 'Precipitação'}

# Modelos polinomiais (graus 1-4, cada variável)
melhor_pol = {'nome': None, 'rmse': np.inf, 'r2': -np.inf, 'grau': None, 'var': None,
              'y_pred': None, 'y_real': None}

for var in variaveis:
    x_tr = df_treino[var].values
    y_tr = df_treino['prod_ton'].values
    x_val = df_validacao[var].values
    y_val_arr = df_validacao['prod_ton'].values
    for grau in [1, 2, 3, 4]:
        coefs = pb.polyfit(x_tr, y_tr, grau)
        y_pred_val_pol = pb.polyval(x_val, coefs)
        rmse_p = np.sqrt(mean_squared_error(y_val_arr, y_pred_val_pol))
        r2_p   = r2_score(y_val_arr, y_pred_val_pol)
        mae_p  = mean_absolute_error(y_val_arr, y_pred_val_pol)
        y_pred_tr = pb.polyval(x_tr, coefs)
        r2_tr = r2_score(y_tr, y_pred_tr)
        resultados_modelos.append({
            'Modelo': f'Polinomial grau {grau} ({nomes_var[var]})',
            'R² Treino': round(r2_tr, 4),
            'R² Validação': round(r2_p, 4),
            'RMSE Validação': round(rmse_p, 2),
            'MAE Validação': round(mae_p, 2),
        })
        if rmse_p < melhor_pol['rmse']:
            melhor_pol.update({'nome': f'Polinomial grau {grau} ({nomes_var[var]})',
                               'rmse': rmse_p, 'r2': r2_p, 'grau': grau,
                               'var': var, 'coefs': coefs,
                               'y_pred': y_pred_val_pol, 'y_real': y_val_arr})

# Regressão Múltipla (4 variáveis)
y_pred_mult = modelo_stats.predict(X_val_sm)
resultados_modelos.append({
    'Modelo': 'Regressão Múltipla (4 variáveis)',
    'R² Treino': round(r2_score(y_treino, modelo_stats.fittedvalues), 4),
    'R² Validação': round(r2_score(y_val, y_pred_mult), 4),
    'RMSE Validação': round(np.sqrt(mean_squared_error(y_val, y_pred_mult)), 2),
    'MAE Validação': round(mean_absolute_error(y_val, y_pred_mult), 2),
})

# Regressão Múltipla (Temperatura + Focos)
combo_red = ['Temp_Max_Media', 'Total_Focos']
sc_red = StandardScaler()
X_tr_red = sm.add_constant(pd.DataFrame(sc_red.fit_transform(df_treino[combo_red]),
                                         columns=combo_red, index=df_treino.index))
X_vl_red = sm.add_constant(pd.DataFrame(sc_red.transform(df_validacao[combo_red]),
                                         columns=combo_red, index=df_validacao.index))
modelo_red = sm.OLS(y_treino, X_tr_red).fit()
yp_red = modelo_red.predict(X_vl_red)
resultados_modelos.append({
    'Modelo': 'Regressão Múltipla (Temperatura + Focos)',
    'R² Treino': round(r2_score(y_treino, modelo_red.fittedvalues), 4),
    'R² Validação': round(r2_score(y_val, yp_red), 4),
    'RMSE Validação': round(np.sqrt(mean_squared_error(y_val, yp_red)), 2),
    'MAE Validação': round(mean_absolute_error(y_val, yp_red), 2),
})

df_comp = pd.DataFrame(resultados_modelos).sort_values('RMSE Validação')
display(df_comp.reset_index(drop=True))
print(df_comp.reset_index(drop=True).to_markdown(index=False))

melhor_linha = df_comp.iloc[0]
print(f"\n Melhor modelo: {melhor_linha['Modelo']}")
print(f"   RMSE={melhor_linha['RMSE Validação']} | R²={melhor_linha['R² Validação']}")

# Guardar modelo vencedor para análise de resíduos
# Com base nos resultados anteriores, o vencedor é Temperatura + Focos
modelo_melhor = modelo_red
y_hat_val_melhor = yp_red

"""O **melhor modelo** pelo critério de menor RMSE de validação foi a **Regressão Múltipla (Temperatura + Focos + Precipitação)**:

| Métrica | Valor |
|---|---|
| R² Treino | 0,0031 |
| R² Validação | −38,13 |
| RMSE Validação | 1.869,43 ton |
| MAE Validação | 1.781,65 ton |

O R² de validação negativo em **todos** os modelos é consequência direta da extrapolação temporal e não deve ser interpretado isoladamente. Em termos de erro absoluto, o melhor modelo erra em média ~1.782 ton, contra ~2.913 ton do modelo com 4 variáveis — uma redução de **39%** no MAE apenas pela escolha melhorada dos preditores.

Padrões notáveis na tabela:
- Modelos simples (grau 1, poucas variáveis) generalizam melhor que modelos complexos
- Polinomiais de grau ≥ 2 com Focos, Dias Secos e Temperatura sofrem colapso severo na validação (RMSE de milhares de toneladas), por extrapolarem curvas ajustadas a intervalos estreitos de treino
- Adicionar Dias Secos às combinações consistentemente piora o RMSE de validação, apesar de ser a variável com maior correlação (r = 0,353) com a produção no treino

## Análise de Resíduos e Previsões — Melhor Modelo Polinomial
---
A análise de resíduos e previsões é conduzida sobre o **modelo vencedor da tabela**: **Regressão Múltipla (Temperatura + Focos)**, o modelo reduzido trabalhado na seção anterior. São avaliados os pressupostos clássicos da regressão linear — normalidade, homocedasticidade e independência dos resíduos — sobre os dados de treino, e apresentadas as previsões para o conjunto de validação (2022–2024).
"""

residuos_treino = modelo_melhor.resid
y_hat_treino    = modelo_melhor.fittedvalues
y_hat_val       = y_hat_val_melhor
y_vl            = y_val.values

print(f"Modelo: Regressão Múltipla (Temperatura + Focos)")
print(f"RMSE Validação: {np.sqrt(mean_squared_error(y_val, y_hat_val_melhor)):.2f} | "
      f"MAE Validação: {mean_absolute_error(y_val, y_hat_val_melhor):.2f}")
print()

# Testes nos resíduos de treino
stat_sw, p_sw = stats.shapiro(residuos_treino)
print(f"Normalidade (Shapiro-Wilk): p-value = {p_sw:.4f}",
      'Normal' if p_sw > 0.05 else 'Não normal')

bp_test = sms.het_breuschpagan(residuos_treino, modelo_melhor.model.exog)
print(f"Homocedasticidade (Breusch-Pagan): p-value = {bp_test[1]:.4f}",
      'OK' if bp_test[1] > 0.05 else 'Heterocedasticidade')

dw = durbin_watson(residuos_treino)
print(f"Independência (Durbin-Watson): {dw:.3f}",
      'OK' if 1.5 < dw < 2.5 else 'Possível autocorrelação')

# Painel de gráficos
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
fig.suptitle('Análise de Resíduos — Regressão Múltipla (Temperatura + Focos)',
             fontsize=13, fontweight='bold')

# 1. Histograma
axes[0,0].hist(residuos_treino, bins=6, edgecolor='black', color='steelblue')
axes[0,0].set_title('Histograma dos Resíduos (Treino)')
axes[0,0].set_xlabel('Resíduo'); axes[0,0].set_ylabel('Frequência')

# 2. QQ-Plot
stats.probplot(residuos_treino, dist='norm', plot=axes[0,1])
axes[0,1].set_title('QQ-Plot dos Resíduos (Treino)')

# 3. Resíduos vs Ajustados
axes[0,2].scatter(y_hat_treino, residuos_treino, color='steelblue')
axes[0,2].axhline(0, color='red', linestyle='--')
axes[0,2].set_title('Resíduos vs Ajustados (Treino)')
axes[0,2].set_xlabel('Valores Ajustados (ŷ)'); axes[0,2].set_ylabel('Resíduos')

# 4. Resíduos ao longo do tempo
axes[1,0].plot(df_treino['ano'].values, residuos_treino, marker='o', color='steelblue')
axes[1,0].axhline(0, color='red', linestyle='--')
axes[1,0].set_title('Resíduos ao Longo do Tempo (Treino)')
axes[1,0].set_xlabel('Ano'); axes[1,0].set_ylabel('Resíduos')

# 5. Real vs Previsto — Treino
axes[1,1].scatter(y_treino, y_hat_treino, color='steelblue', label='Treino')
lim = [min(float(y_treino.min()), float(y_hat_treino.min())) - 200,
       max(float(y_treino.max()), float(y_hat_treino.max())) + 200]
axes[1,1].plot(lim, lim, 'r--', label='Linha perfeita')
axes[1,1].set_title('Real vs Previsto (Treino)')
axes[1,1].set_xlabel('Produção Real (ton)'); axes[1,1].set_ylabel('Produção Prevista (ton)')
axes[1,1].legend()

# 6. Real vs Previsto — Validação
axes[1,2].scatter(y_vl, y_hat_val, color='darkorange', label='Validação')
axes[1,2].plot(lim, lim, 'r--', label='Linha perfeita')
for ano, real, prev in zip(df_validacao['ano'].values, y_vl, y_hat_val):
    axes[1,2].annotate(str(ano), (real, prev), textcoords='offset points', xytext=(5,5), fontsize=9)
axes[1,2].set_title('Real vs Previsto (Validação)')
axes[1,2].set_xlabel('Produção Real (ton)'); axes[1,2].set_ylabel('Produção Prevista (ton)')
axes[1,2].legend()

plt.tight_layout()
plt.show()

"""**Normalidade (Shapiro-Wilk):** p-value = **0,3821** (> 0,05) — não se rejeita a hipótese nula; os resíduos seguem distribuição aproximadamente normal.

**Homocedasticidade (Breusch-Pagan):** p-value = **0,2669** (> 0,05), a variância dos resíduos é constante ao longo dos valores ajustados — sem heterocedasticidade.

**Independência (Durbin-Watson):** estatística = **2,509** — um pouco acima do limite superior convencional de 2,5, indicando leve indício de autocorrelação negativa nos resíduos. Esse resultado deve ser interpretado com cautela dado o tamanho reduzido da amostra (8 pontos de treino).

Visualmente, o histograma e o QQ-plot sugerem normalidade aproximada. O gráfico de resíduos vs. ajustados não evidencia padrão sistemático relevante. Na validação (2022–2024), o modelo subestima consistentemente a produção.
"""

print('Previsões do melhor modelo polinomial — conjunto de validação (2022–2024)\n')

df_resultados = pd.DataFrame({
    'Ano': df_validacao['ano'].values,
    'Producao_Real_ton': y_vl_best,
    'Previsao_Modelo_ton': np.round(y_hat_val_best, 2),
    'Residuo': np.round(y_vl_best - y_hat_val_best, 2)
})

display(df_resultados)

df_resultados.to_csv('previsoes_validacao_PA.csv', index=False)
print("Arquivo 'previsoes_validacao_PA.csv' gerado com sucesso!")

"""As previsões para os anos de validação mostram que o modelo subestimou a produção em todos os três anos:

| Ano | Real (ton) | Previsto (ton) | Resíduo (ton) |
|---|---|---|---|
| 2022 | 8.808 | 6.970,38 | +1.837,62 |
| 2023 | 9.394 | 6.982,28 | +2.411,72 |
| 2024 | 8.721 | 7.120,48 | +1.600,52 |

Os resíduos positivos e consistentes indicam que o modelo tende a subestimar a produção dos anos mais recentes. Isso pode refletir uma tendência de crescimento da produção no período de validação não capturada pelos preditores climáticos disponíveis, reforçando a necessidade de incorporar um conjunto de dados mais amplo para modelagem efetiva.

"""